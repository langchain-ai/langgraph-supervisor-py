from __future__ import annotations

import json
import logging
import os
from typing import Dict, List, Optional, Any

from whats_eat.app.env_loader import load_env
from neo4j import GraphDatabase
from sentence_transformers import SentenceTransformer


# Load environment variables including .env.json
load_env()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RAGAgent:
    def __init__(self) -> None:
        # Neo4j connection
        self.neo4j_uri: str = os.getenv("NEO4J_URI", "bolt://localhost:7687")
        self.neo4j_user: str = os.getenv("NEO4J_USER", "neo4j")
        self.neo4j_password: Optional[str] = os.getenv("NEO4J_PASSWORD")
        self.neo4j_driver = None

        # Pinecone connection
        self.pinecone_api_key: Optional[str] = os.getenv("PINECONE_API_KEY")
        self.pinecone_environment: Optional[str] = os.getenv("PINECONE_ENVIRONMENT")
        self.index_name: str = "places-index"

        # Pinecone runtime handles (lazy init) â€” supports new and legacy SDKs
        self._pinecone_client: Optional[object] = None
        self._pinecone_index: Optional[object] = None
        self._pinecone_new_sdk: bool = False

        # Embedding model
        self.model = SentenceTransformer("all-MiniLM-L6-v2")
        logger.info("Initialized RAG agent")
        logger.info(f"Neo4j URI: {self.neo4j_uri}")
        logger.info(f"Neo4j password present: {bool(self.neo4j_password)}")
        logger.info(f"Pinecone API key present: {bool(self.pinecone_api_key)}")
        logger.info(f"Pinecone environment: {self.pinecone_environment}")

    # ----------------------- Neo4j -----------------------
    def connect_neo4j(self) -> None:
        """Connect to Neo4j using environment variables."""
        if not self.neo4j_password:
            raise ValueError("NEO4J_PASSWORD is required but missing in environment")
        try:
            self.neo4j_driver = GraphDatabase.driver(
                self.neo4j_uri, auth=(self.neo4j_user, self.neo4j_password)
            )
            logger.info("Connected to Neo4j")
        except Exception as e:
            logger.error(f"Failed to connect to Neo4j: {e}")
            raise

    # --------------------- Pinecone ----------------------
    def connect_pinecone(self) -> None:
        """Initialize Pinecone, preferring the new SDK and falling back to legacy."""
        if not self.pinecone_api_key:
            raise ValueError("Missing PINECONE_API_KEY in environment")

        # Infer cloud/region from PINECONE_ENVIRONMENT (e.g., us-east-1-aws)
        cloud = "aws"
        region: Optional[str] = None
        if self.pinecone_environment:
            env_l = self.pinecone_environment.lower()
            if env_l.endswith("-aws"):
                cloud, region = "aws", env_l[:-4]
            elif env_l.endswith("-gcp"):
                cloud, region = "gcp", env_l[:-4]
            elif env_l.endswith("-azure"):
                cloud, region = "azure", env_l[:-6]
            else:
                region = env_l

        try:
            # Try new SDK first
            from pinecone import Pinecone as _Pinecone  # type: ignore
            from pinecone import ServerlessSpec as _ServerlessSpec  # type: ignore

            pc = _Pinecone(api_key=self.pinecone_api_key)
            existing = [ix.name for ix in pc.list_indexes()]
            if self.index_name not in existing:
                if not region:
                    region = "us-east-1"
                pc.create_index(
                    name=self.index_name,
                    dimension=384,
                    metric="cosine",
                    spec=_ServerlessSpec(cloud=cloud, region=region),
                )
            self._pinecone_index = pc.Index(self.index_name)
            self._pinecone_client = pc
            self._pinecone_new_sdk = True
            logger.info("Initialized Pinecone (new SDK)")
        except Exception as new_err:
            # Fallback to legacy SDK if available
            try:
                import importlib

                pinecone_legacy = importlib.import_module("pinecone")
                pinecone_legacy.init(
                    api_key=self.pinecone_api_key, environment=self.pinecone_environment
                )
                if self.index_name not in pinecone_legacy.list_indexes():
                    pinecone_legacy.create_index(
                        name=self.index_name, dimension=384, metric="cosine"
                    )
                self._pinecone_index = pinecone_legacy.Index(self.index_name)
                self._pinecone_client = pinecone_legacy
                self._pinecone_new_sdk = False
                logger.info("Initialized Pinecone (legacy SDK)")
            except Exception as legacy_err:
                # Provide a clearer hint if the error likely stems from SDK rename
                msg = str(new_err) if new_err else ""
                if "pinecone-client" in msg or "renamed from `pinecone-client`" in msg:
                    raise RuntimeError(
                        "Pinecone SDK conflict: uninstall 'pinecone-client' and install 'pinecone' (new SDK)."
                    ) from new_err
                raise legacy_err

    # --------------------- Utilities ---------------------
    def load_json_data(self, file_path: str) -> Any:
        """Read a JSON file and return parsed data (dict or list)."""
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)

    def _normalize_place(self, raw: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Normalize incoming place record to expected schema.

        Supports two formats:
        - Google Places-like: has keys place_id, name, formatted_address, rating, types, reviews
        - Test format (tests/test.json): keys id, displayName.text, formattedAddress
        """
        if not isinstance(raw, dict):
            return None

        if "place_id" in raw and "name" in raw:
            return raw

        # Try test format mapping
        pid = raw.get("id")
        dname = raw.get("displayName") or {}
        name = (dname.get("text") if isinstance(dname, dict) else None) or raw.get("name")
        addr = raw.get("formattedAddress") or raw.get("formatted_address")
        if pid and name:
            return {
                "place_id": pid,
                "name": name,
                "formatted_address": addr or "",
                "types": [],
                "rating": 0.0,
                "reviews": [],
            }
        return None

    # ---------------------- Ingest -----------------------
    def create_knowledge_graph(self, place_data: Dict[str, Any]) -> None:
        """Write place and (optionally) reviews into Neo4j."""
        if not self.neo4j_driver:
            raise ValueError("Neo4j is not connected; call connect_neo4j() first")

        with self.neo4j_driver.session() as session:
            session.run(
                """
                CREATE (p:Place {
                    place_id: $place_id,
                    name: $name,
                    address: $address,
                    rating: $rating,
                    types: $types
                })
                """,
                {
                    "place_id": place_data["place_id"],
                    "name": place_data["name"],
                    "address": place_data.get("formatted_address", ""),
                    "rating": place_data.get("rating", 0.0),
                    "types": place_data.get("types", []),
                },
            )

            if "reviews" in place_data:
                for r in place_data["reviews"]:
                    session.run(
                        """
                        MATCH (p:Place {place_id: $place_id})
                        CREATE (rv:Review {
                            author_name: $author_name,
                            rating: $rating,
                            text: $text,
                            time: $time
                        })
                        CREATE (rv)-[:REVIEWS]->(p)
                        """,
                        {
                            "place_id": place_data["place_id"],
                            "author_name": r.get("author_name"),
                            "rating": r.get("rating"),
                            "text": r.get("text"),
                            "time": r.get("time"),
                        },
                    )

        logger.info(f"KG upserted for place: {place_data.get('name')}")

    def create_embeddings(self, place_data: Dict[str, Any]) -> None:
        """Encode a textual representation and upsert into Pinecone."""
        parts: List[str] = [
            str(place_data.get("name", "")),
            str(place_data.get("formatted_address", "")),
            "Types: " + ", ".join(place_data.get("types", []) or []),
        ]
        if "reviews" in place_data and place_data["reviews"]:
            reviews_text = " ".join(str(rv.get("text", "")) for rv in place_data["reviews"]).strip()
            if reviews_text:
                parts.append("Reviews: " + reviews_text)

        text_representation = " ".join(p for p in parts if p).strip()
        embedding = self.model.encode(text_representation)

        if not self._pinecone_index:
            # Allow implicit init if caller forgot connect_pinecone
            self.connect_pinecone()

        if self._pinecone_new_sdk:
            self._pinecone_index.upsert(
                vectors=[
                    {
                        "id": place_data["place_id"],
                        "values": embedding.tolist(),
                        "metadata": {
                            "name": place_data.get("name"),
                            "address": place_data.get("formatted_address", ""),
                            "rating": place_data.get("rating", 0.0),
                        },
                    }
                ]
            )
        else:
            # Legacy SDK tuple style
            self._pinecone_index.upsert(
                vectors=[
                    (
                        place_data["place_id"],
                        embedding.tolist(),
                        {
                            "name": place_data.get("name"),
                            "address": place_data.get("formatted_address", ""),
                            "rating": place_data.get("rating", 0.0),
                        },
                    )
                ]
            )

        logger.info(f"Vector upserted for place: {place_data.get('name')}")

    def process_places_data(self, json_file_path: str, dry_run: bool = False) -> List[Dict[str, Any]]:
        """End-to-end processing: load JSON, normalize, optionally connect, and upsert.

        Returns the list of normalized place docs processed.
        """
        data = self.load_json_data(json_file_path)
        if isinstance(data, dict):
            items = data.get("results", [])
        elif isinstance(data, list):
            items = data
        else:
            items = []

        normalized: List[Dict[str, Any]] = []
        for raw in items:
            doc = self._normalize_place(raw)
            if doc:
                normalized.append(doc)

        if not dry_run:
            self.connect_neo4j()
            self.connect_pinecone()
            for place in normalized:
                self.create_knowledge_graph(place)
                self.create_embeddings(place)
            logger.info("Finished processing places JSON: KG + embeddings upserted")
        else:
            logger.info(f"Dry run: would process {len(normalized)} places (no external connections)")

        return normalized

    # ---------------------- Query ------------------------
    def query_similar_places(self, query_text: str, top_k: int = 5) -> Any:
        """Encode the query and perform Pinecone vector search."""
        query_embedding = self.model.encode(query_text).tolist()
        if not self._pinecone_index:
            self.connect_pinecone()
        return self._pinecone_index.query(
            vector=query_embedding, top_k=top_k, include_metadata=True
        )


if __name__ == "__main__":
    # CLI: allow running the agent with a JSON file path
    import argparse
    import sys

    parser = argparse.ArgumentParser(
        prog="RAGAgent",
        description=(
            "Process Places-style JSON and store knowledge graph + embeddings; "
            "then you can query with query_similar_places()."
        ),
    )
    parser.add_argument(
        "json_file",
        nargs="?",
        help="Path to places JSON file to process (optional)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Parse and normalize only; skip Neo4j/Pinecone connections",
    )

    args = parser.parse_args()
    agent = RAGAgent()

    if args.json_file:
        processed = agent.process_places_data(args.json_file, dry_run=args.dry_run)
        if args.dry_run:
            # Print a compact preview of normalized docs
            preview = [
                {"place_id": d.get("place_id"), "name": d.get("name"), "address": d.get("formatted_address")}
                for d in processed
            ]
            print(json.dumps(preview, ensure_ascii=False, indent=2))
    else:
        print(
            "No JSON file provided. You can run the module as:\n"
            "  py -m whats_eat.agents.RAG_agent path\\to\\places.json\n"
            "or:\n"
            "  py whats_eat\\agents\\RAG_agent.py path\\to\\places.json"
        )
        sys.exit(2)
